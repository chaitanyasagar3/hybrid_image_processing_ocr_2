# hybrid_image_processing_ocr_2

Hybrid Image Processing for Optical Character Recognition



Chaitanya Sagar
New Jersey Institute of Technology
Image Processing
Dr. Frank Shih
Date : May 1 2022






Abstract
This paper looks at a newly emerging field in the tech world, image processing. It is specifically structured to have the field of image recognition and processing keenly studied, the methods that have so far been invented in the field, and the newer ways in which the methods would be significantly improved to be as concise and precise as possible. In the article, the various application areas of image processing are dealt with in-depth, and as such, my view of a new method to approach the field shall be provided. 
Introduction
From the invention of science and its various disciplines, there have been several advancements in the computing field, from the invention of the abacus to where the world stands today. The years and even centuries of stipulated studies in the field have brought so many concepts, some of which were way ahead of their time in disciplines such as machine learning. It was not until later years, over a hundred, that computer scientists gave it a keener look. They came up with ways to advance into the field with greater zeal and research not lesser than their predecessors, only that now it was aided by the improved computer capabilities in the 21st century. The more significant investment in computer cores to multicore computers capable of multiprocessing advanced the scientific study of machine learning in magnitudes incomparable to history. This, later on, increased the diversification into the much broader field of artificial intelligence, a term often used to describe any test abstracted from human intervention and requires a higher degree of processing power than the human brain is not capable of yet. However, it transcends beyond as simple as a single sentence of description.
Image processing came up where a not-so-clear image could be analyzed, and its unclear intricacies cleared out to be a clear image as it was initially. The image characters embedded can now be deciphered and presented as precise writing. Nowadays, image processing has come a long way to provide helpful information on images previously thought not to be understandable by the human eye. There are two ways we can classify the image processing taskâ€”either analog or digital techniques. They are still used but later be predicated; in my view, the analog technique involves using images and photographs. They are taken up and stored to be "cleaned" to come up with an understanding of what it entails. Digital image processing is the newer and more powerful way of approaching image processing. Here, the image is presented as a matrix, with every matrix component representing a feature of the image to be processed. The features described here are the pixels. The matrix representation of image features forms our basis of image processing. In the single simplest abstraction of an image, in the article below, I will deal with the various methods invented to go deeper into the image processing field. 
1.	Term definition
Pixels are a group of small, personally identifying cells breakdown of an image into parts and allow computers to process images. Binary images, color pictures, and grayscale images are all referred to as digital images as far as the task of processing images is concerned (Pixels Fisher et al.). (1996). Pixels present in binary pictures can be taken up as either of two options, either black or white as the 1 and 0 states, although this could alter depending on whether the foreground or background color is white or black. (Fisher et al.1996). Mathematical morphology, like linguistics, is based on mathematical ideas. This is somewhat true in digital image processing, where ideas like set theory and other concepts like image enhancement, edge detection, and segmentation are used to analyze binary images and perform noise reduction (Fisher et al. 1996). In this work, structural elements, also known as kernels, are more useful in the preprocessing patterns involved in image recognition.
The methods available
1.1 Cascade(Haar-like)
 Scientific demonstrations by Soo show how to locate items in photos using Haar Cascade classifiers. According to Viola and Jones, object recognition is as intensively valuable for the study of image processing to the members of the computer science ecosystem and those that are not really in the field, the tech enthusiasts with a certain degree of curiosity in the field Viola & Jones 2001). 
The Haar Cascade algorithm is one of the algorithms that come in handy when deciding how we can chart a path into character recognition in trying to process an image. It is proven to be a method with minimized complexity in time, unlike the other methods. This happens even as the algorithm goes a long way to improve the recognition of the various objects present in an image.The Haar classifier has an advantage over the other algorithm methods as it tackles some basic incapacitations evident in the other methods. Classification of color is one such incapacitation dealt with. This is the continuous updating of image color as constantly as possible. Color classification required continuous updates in a live application where a soccer match had to be played by robots, according to Lovell and Estivill-Castro (Lovell & Estivill-Castro 2007). The method employs characteristics to speed up procedures and make model training easier in Viola and Jones design elements like Papageorgiou, whose functionality is governed by the dimensions of the rectangular-shaped pixels on the picture below (Soo 2014).
 

A and B are two-rectangle properties that can be used to compute the difference in pixel addition inside rectangular regions. Three-rectangle features are denoted by the letter C. The sum of the exterior rectangles is taken out of the picture frame to arrive at the answer. D stands for the 4-rectangle feature, subtracting the sums of diagonally opposed rectangles from the analysis (Viola &Jones, 2001; Soo, 2014).
1.2 Binarization
This algorithm should consider the differences between binary, grayscale, and color pictures. Thresholding is a typical binarization technique. Before producing a bitwise image output, this image processing approach separates a color or grayscale image into segments (Fisher et al. 1996).
The approach can help us differentiate between picture bits that are significant for a specific output and those that aren't. Depending on the image type, black pixels can represent either the background or the foreground, as seen in the photographs below from Sajjad (Sajjad 2010). The intensity threshold setting controls the image's division into portions.


  

The concept of intensity threshold comes a whole lot in this method. According to Pratt,  the intensity of some colors on the image enables the matching of specific colors to a given level of hue in black and white as the only two binary colors available. This eases the process of character recognition on the image (Pratt 2013).
As the name suggests, bilevel Luminance Thresholding involves several color brightness and their matching to certain levels on the hue scale, and thresholding becomes even more necessary than lower brightness images. An example of the black and white intensity matching is the one shown below:
 

In Pratt's view, the main issue could be how to determine the intensity with which we apply the threshold because the threshold may still have some noise, whereas setting the threshold at a very high intensity overdoes some parts of the characters on the image and regions may become over-dilated (Pratt 2013). Although the Otsu thresholding technique has addressed some of the concerns that come with threshold matching, more scientific research is being done on the topic, and more significant improvements are in a line of vision (Otsu 1979)
1.3 Inversion (Digital type)
In the development of the O.C.R., there is a need to preprocess the image and have the color scales inverted to certain degrees. According to Rao, the color inversion process is an improved level of the binarization process. It only makes it easier to do specific tasks on the image, such as extracting features, segmenting the image, and so many other processes that come into character recognition afterward (Rao et al. 2016).
The bitwise-NOT operation in image processing is a method that cascades inverted color types to the colors present on the image. Let's say the brighter colors are mapped onto, the darker colors of the spectrum and vice versa. The black color is automatically changed to white, and the dark ones are inverted to white. (Fisher et al. 1996). The method takes in the bit like converting the image pixels and transforming them when run. The thresholding process comes in handy at this point for intensity matching and inverting. The method opts for bitwise preprocessing stead of gray-level capturing of any image. The truth table used to convert the image bits is 0 mapped as one, and the inverse, zero, is taken to be a one ( Jain 2003). This implies that the image's polarity is altered by this action.
HYBRID PREPROCESSING METHODS APPLIED IN THE OCR
OCR in full stands for Optical Character Recognition. The whole technology of the O.C.R. revolves around converting the images that have been processed into machine-level language text. We can say that it changes the images to a binary format for them to be clearly understood and manipulated by the computer. The O.C.R. is a technology improvement that cuts across almost all the other image processing methods. The following are the main capabilities incorporated in the O.C.R. as a whole. 
CAPABILITIES
a)	Scaling the image
b)	Skew adjustment of the image being processed
c)	Binarization of the image
d)	Noise removing capability
a) scaling the image
At times, the image to be processed is in a specific size that cannot be processed to get the characters that have been written on the image very well. The O.C.R. has the capability of what we would term as zooming in on the image and having the image resized to a viable scale for it to be processed and the characters made out with as little ease as possible. 
b) skew adjustment
The O.C.R. technology has the capability of skewing the image for easier processing. What do we mean by skewing? Sometimes an image to be processed may be aligned in a way that the
O.C.R. cannot decipher or process the text in the image very well. This is because the text letters in the image have been aligned in a way that cannot be recognized as straight letters and thus really have to be in an alignment that can identify them as alphabets. The O.C.R. has an incorporated method/function that takes in the image element frame as the parameters and realigns them to fit the page's straight alignment.
c) binarization of the image
What is binarization in the context of O.C.R. technology? This is the image processing as either black or white, and as such, the whole image is recolored to black for non-text content and white for the text content. The binarization method is an independent image recognition method, and the O.C.R. incorporates this method in its work. It's like the most fundamental working of any O.C.R. The whole image is broken down into pixel components, and parts that meet a certain predefined threshold persist with a specific color. The ones that fall below take the binary opposite of the color, like black or white depending on the O.C.R. binarization method configuration. Libraries such as OpenCV in python come with so many out of the bag implementation methods that are instrumental in the binarization process. 
d) Noise Removal 
In its most fundamental description, noise is anything that is not wanted and is unnecessary in an image. To a technical level, this is just the presence of pixels on the image that exhibit a discontinuous color with the adjacent colors. When the pixels pile up to level numbers, they form an unwanted variation in the image quality, primarily if the distortions lie in the characters to be processed by the O.C.R. The whole duty of noise removal or, in other terms, denoising is done in the O.C.R. Salt, and pepper noise is different from Gaussian noise. Gaussian noise can be termed to bring about the blur in an image. To a significant level, if the pixels that bring forth the characters in an image have the Gaussian noise, the text format cannot be deciphered or processed (Evtimov et al. 2019. This is where the O.C.R. has an incorporated function to readjust the pixels' color that brings about the noise to match the adjacent pixels as much as possible and thus clear out the image for character recognition. 
I had to think about a specific use case when developing a part capable of biometric authentication and character recognition (O.C.R.). The initial use case was to utilize these capabilities to identify an individual by face and then scan personal I.D. to avoid this need for physical interaction during a security check in an organization. After some thought, I came up with an even better application for these tools. Face detection and character recognition were used in this use case to aid in the contactless delivery of parcels. I choose to implement in two main steps using an IDE of choice though more preference is given to Pycharm IDE. The first would be facial recognition, which would go a long way to identify the parcel's selector securely. To avoid tricksters, as Evtimov has shown, may penetrate facial recognition, this stage would be followed by entering random numbers created (Evtimov et al. 2019).
The approach is a hybrid of as many class methods and functions as present in tesseract, OpenCV, and the main library used in data science as Numpy, focusing on cascade preprocessing as mentioned previously in the paper and color conversion methods to make preparation easier. Pytessaract takes care of the heavy labor to guarantee that our content is extracted with a 70 percent confidence level.
The algorithm can then insert an image of the delivery receipt once we have the image of the individual picking up the parcel. The central assumption is that we are working on the actual receipt template as an image similar to the one below.The critical duty now is to have the image of the parcel processed and later on have the number of deliveries quantified and delivered for use by other departments inside the company, such as logistics, finance, etc. The system is operated via the terminal, and it still works. The whole thought process that came to formulating the algorithm is to have it work regardless of the form of data provided as parameters.
2.	COMPARING THE METHOD WITH EXISTING ONES
The algorithm is very intensive as far as the processor demands are concerned. It could be improved a great deal if other method algorithms are like where Otsu's were used and some preprocessing techniques. Sajjad proposes a particular text recognition use case that includes the bitwise NOT function. It works better for text with a predetermined format, such as number plates, but it may degrade the quality of output for our method (Sajjad 2010). The O.C.R.'s many notable differences from the other image processing methods in character recognition are outlined below. 
1.	Higher processing power.
2.	Highly complex.
3.	More costly to implement
4.	Higher accuracy 


1.) Higher Processing Power
The O.C.R. technology is so sophisticated that it requires the higher processing power of the machine that the algorithm is run on. On the scale, the O.C.R. combines many independent clauses with a cascade of method chains. The methods deal with different aspects of the image processing, such as binarization and skewing of the image in the upright position so that the letters may also be in the correct alignment. The method chains are run simultaneously in the CPU, a process termed multithreading (Rao 2016). This is where not only the primary method is run, but the others too are run simultaneously at the same time; each method's result depends on the previous times. The O.C.R. generally can be described as the total sum of the various image recognition methods. At the start of image processing in the machine learning field of artificial intelligence, the processing power of earlier computers was a real limiting factor. The fact that not so many processing cores were available at the time and the multicore technology was way ahead of its time was a real setback to the invention of the O.C.R. Nowadays, with as many cores as the processing company of the CPU can imagine possible, nanotechnology has smoothened things out to produce higher performance core computers. The other methods of image processing that have low requirements on the CPU processing power are faster but error-prone. When we have a keener look at how the O.C.R. compared to the older analog methods, such as photograph and printout studying that only relied on the camera's ability to decipher the alphabetical letters on the picture(let's say zooming in on the picture taken from afar), the O.C.R. has a greater need for processing speed and power. 

2.) Highly Complex 
Let's look at it this way. The O.C.R. is a cascade of the many independent methods chained in equally as many classes. The OpenCV library implements the many methods responsible for binarization, image skewing, denoising, and many other methods. When used with the Numpy library, primarily used in data science and character recognition being a documented subfield, the two come with so many methods in python language. The two used together on any platform and exceptionally executed on the computer O.C.R. device would mean the boilerplate code is as large as possible. The methods, at times, are run in a multithreaded version as described earlier, thus making the algorithm a little too complicated to follow up on, unlike the independent image processing methods incorporated within it (Rao  2016). One would at times will his way scientifically to carry out the character recognition with independent methods on the same image with each as efficiently as possible, but the O.C.R. runs on as complex systems as there are the complex CPUs out being produced even days on notice. 
c) Cost-Intensive
With the complexity of the coding algorithm implemented in the O.C.R. as the processing power required, the cost shoots as highly. The cost is dependent on the higher processing power required and delivered. The CPU-intensive algorithm requires a multicore CPU that costs a whole lot more (Fisher 1996). This is due to the nanotechnology intricacies that come into play when pushing even a single CPU chip to production that is multicore. Compared to the other methods, especially the analog methods, the cost of the O.C.R. implementation is relatively very high. 
d) Higher Accuracy
If the downsides of the O.C.R. were to outweigh the accuracy it comes with, there would be no need for its execution scientifically. Why would a technology that demands so much CPU processing power, higher cost of implementation, and complexity in making out how it cascades the other character recognition methods even be invented? Well, the higher accuracy is an angle to look at it. Let's say we were to use only the binarization or the image inversion method; it would go as far as only to have specific aspects of the image's character recognition dealt with but not the others (Bradski 2008). The individual methods would fail without the output of other methods if single-handedly used. The O.C.R. multithreaded class methods have the interdependence required to have an eventual output that is hard to refute from the actual character recognition required. 
CONCLUSIONS
This paper demonstrates how to create an algorithm that can receive video input from people and detect faces before using an O.C.R. method to collect text. The use of the collective cascade of the methods involved in image recognition as implemented in the O.C.R. is a great way to address the field in a better way. In summary, at this point, hybrid algorithms appear to be the best option, especially given the amount of research that has been done but has yet to be put to good use.




References
[1]	Bradski, G. and Kaehler, A., 2008. Learning OpenCV: Computer vision with the OpenCV library. "O'Reilly Media, Inc.".
[2]	C. Papageorgiou, M. Oren, and T. Poggio. A general framework for object detection. In International Conference on Computer Vision, 1998.
[3]	Evtimov, I., O'Hair, D., Fernandes, E., Calo, R., and Kobo, T., 2019. Is tricking a robot hacking?. Berkeley Tech. L.J., 34, p.891.
[4]	Fisher, R., Perkins, S., Walker, A. and Wolfart, E., 1996. Hypermedia image processing reference. England: John Wiley & Sons Ltd, pp.118-130.
[5]	Jain, R.P., 2003. Modern digital electronics. Tata McGraw-Hill Education.
[6]	Lovell, N. and Estivill-Castro, V., 2007. Color classification and object recognition for robot soccer under variable illumination. IntechOpen.
[7]	Otsu, N., 1979. A threshold selection method from gray-level histograms. IEEE transactions on systems, man, and cybernetics, 9(1), pp.62-66.
[8]	Rao, N.V., Sastry, A.S.C.S., Chakravarthy, A.S.N. and Kalyanchakravarthi, P., 2016. OPTICAL CHARACTER RECOGNITION TECHNIQUE ALGORITHMS. Journal of Theoretical & Applied Information Technology, 83(2).
[9]	Sajjad, K.M., 2010. Automatic license plate recognition using python and OpenCV. Department of Computer Science and Engineering M.E.S. College of Engineering.
[10]	Soo, S., 2014. Object detection using Haar-cascade Classifier. Institute of Computer Science, University of Tartu, 2(3), pp.1-12
[11]	Viola, P. and Jones, M., 2001, December. Rapid object detection using a boosted cascade of simple features. In Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition. C.V.P.R. 2001 (Vol 1, pp. I-I). Ieee.

